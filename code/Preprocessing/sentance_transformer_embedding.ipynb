{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding essay0\n",
      "\n",
      "********** Data Summary **********\n",
      "\n",
      "(59946, 31) \n",
      "\n",
      "   age     status sex orientation       body_type               diet  \\\n",
      "0   22     single   m    straight  a little extra  strictly anything   \n",
      "1   35     single   m    straight         average       mostly other   \n",
      "2   38  available   m    straight            thin           anything   \n",
      "\n",
      "     drinks      drugs                       education     ethnicity  ...  \\\n",
      "0  socially      never   working on college/university  asian, white  ...   \n",
      "1     often  sometimes           working on space camp         white  ...   \n",
      "2  socially        NaN  graduated from masters program           NaN  ...   \n",
      "\n",
      "                                              essay0  \\\n",
      "0  about me:  i would love to think that i was so...   \n",
      "1  i am a chef: this is what that means. 1. i am ...   \n",
      "2  i'm not ashamed of much, but writing public te...   \n",
      "\n",
      "                                              essay1  \\\n",
      "0  currently working as an international agent fo...   \n",
      "1  dedicating everyday to being an unbelievable b...   \n",
      "2  i make nerdy software for musicians, artists, ...   \n",
      "\n",
      "                                              essay2  \\\n",
      "0  making people laugh. ranting about a good salt...   \n",
      "1  being silly. having ridiculous amonts of fun w...   \n",
      "2  improvising in different contexts. alternating...   \n",
      "\n",
      "                                              essay3  \\\n",
      "0  the way i look. i am a six foot half asian, ha...   \n",
      "1                                                NaN   \n",
      "2  my large jaw and large glasses are the physica...   \n",
      "\n",
      "                                              essay4  \\\n",
      "0  books: absurdistan, the republic, of mice and ...   \n",
      "1  i am die hard christopher moore fan. i don't r...   \n",
      "2  okay this is where the cultural matrix gets so...   \n",
      "\n",
      "                                              essay5  \\\n",
      "0                  food. water. cell phone. shelter.   \n",
      "1  delicious porkness in all of its glories. my b...   \n",
      "2  movement conversation creation contemplation t...   \n",
      "\n",
      "                        essay6  \\\n",
      "0  duality and humorous things   \n",
      "1                          NaN   \n",
      "2                          NaN   \n",
      "\n",
      "                                              essay7  \\\n",
      "0  trying to find someone to hang out with. i am ...   \n",
      "1                                                NaN   \n",
      "2  viewing. listening. dancing. talking. drinking...   \n",
      "\n",
      "                                              essay8  \\\n",
      "0  i am new to california and looking for someone...   \n",
      "1  i am very open and will share just about anyth...   \n",
      "2  when i was five years old, i was known as \"the...   \n",
      "\n",
      "                                              essay9  \n",
      "0  you want to be swept off your feet! you are ti...  \n",
      "1                                                NaN  \n",
      "2  you are bright, open, intense, silly, ironic, ...  \n",
      "\n",
      "[3 rows x 31 columns] \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n",
      "\n",
      "********** Data Shape after Removing Duplicates **********\n",
      "\n",
      "(59946, 31) \n",
      "\n",
      "********** Count of Null Values for Each Column **********\n",
      "\n",
      "sign      0\n",
      "essay0    0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "********** Data Shape after Removing Null Values **********\n",
      "\n",
      "(48890, 2) \n",
      "\n",
      "\n",
      "********** Class Label Distribution **********\n",
      "\n",
      "sign\n",
      "leo            4374\n",
      "gemini         4310\n",
      "libra          4207\n",
      "cancer         4206\n",
      "virgo          4141\n",
      "taurus         4140\n",
      "scorpio        4134\n",
      "aries          3989\n",
      "pisces         3946\n",
      "sagittarius    3942\n",
      "aquarius       3928\n",
      "capricorn      3573\n",
      "Name: count, dtype: int64\n",
      "(48890,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def load_data(file_name, col_name, log_path = 'output/tmp.txt'):\n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "\n",
    "    root_dir: a path for data directory\n",
    "    datafile: a text file for saving output\n",
    "\n",
    "    return: X and y dataframe\n",
    "    \"\"\"\n",
    "    output_file = open(log_path, 'a')\n",
    "    df = pd.read_csv(file_name)\n",
    "    print(\"\\n********** Data Summary **********\\n\")\n",
    "    print(df.shape, \"\\n\")\n",
    "    print(df.head(3), \"\\n\")\n",
    "    print(df.info(), \"\\n\")\n",
    "\n",
    "    print(\"\\n********** Data Summary **********\\n\", file=output_file)\n",
    "    print(df.shape, \"\\n\", file=output_file)\n",
    "    print(df.head(3), \"\\n\", file=output_file)\n",
    "    print(df.info(), \"\\n\", file=output_file)\n",
    "    ## Remove duplicates if any and keep first occurrence\n",
    "    # df.drop_duplicates(subset=['pmid'], keep='first', inplace=True)\n",
    "\n",
    "    print(\"\\n********** Data Shape after Removing Duplicates **********\\n\")\n",
    "    print(df.shape, \"\\n\")\n",
    "\n",
    "    print(\"\\n********** Data Shape after Removing Duplicates **********\\n\", file=output_file)\n",
    "    print(df.shape, \"\\n\", file=output_file)\n",
    "\n",
    "    # if col_name == 'mix':\n",
    "    #     df['mix'] = df['title'] + df['abstract']\n",
    "    ## clean the sign column\n",
    "    df['sign'] = df['sign'].apply(lambda x: str(x).split(' ')[0])\n",
    "    df = df[df['sign'] != 'nan']\n",
    "\n",
    "    df = df[['sign', col_name]]\n",
    "    df[col_name] = df[col_name].fillna('')\n",
    "    ## Check if any columns contain null values\n",
    "    print(\"\\n********** Count of Null Values for Each Column **********\\n\")\n",
    "    print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "    print(\"\\n********** Count of Null Values for Each Column **********\\n\", file=output_file)\n",
    "    print(df.isnull().sum(), \"\\n\", file=output_file)\n",
    "\n",
    "    ## Drop instances including null values\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"\\n********** Data Shape after Removing Null Values **********\\n\")\n",
    "    print(df.shape, \"\\n\")\n",
    "\n",
    "    print(\"\\n********** Data Shape after Removing Null Values **********\\n\", file=output_file)\n",
    "    print(df.shape, \"\\n\", file=output_file)\n",
    "\n",
    "    print(\"\\n********** Class Label Distribution **********\\n\")\n",
    "    print(df[\"sign\"].value_counts())\n",
    "\n",
    "    print(\"\\n********** Class Label Distribution **********\\n\", file=output_file)\n",
    "    print(df[\"sign\"].value_counts(), file=output_file)\n",
    "    ## Trim unnecessary spaces for strings\n",
    "    df[col_name] = df[col_name].apply(lambda x: str(x).strip())\n",
    "    df = df.reset_index(drop=True)\n",
    "    ## Split into X and y (target)\n",
    "    X, y = df.loc[:, col_name], df.loc[:, 'sign']\n",
    "    output_file.close()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "transformer = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "data_path = '../data/okcupid_profiles.csv'\n",
    "col_name = 'essay0'\n",
    "log_path = '../output/tmp.txt'\n",
    "for col_name in [f'essay{i}' for i in range(0, 10)]:\n",
    "    print(f'embedding {col_name}')\n",
    "    X, y = load_data(data_path, col_name, log_path)\n",
    "    X = transformer.encode(X)\n",
    "    with open(f\"../embeddings/transformer/transformer_{col_name}.pickle\", \"wb\") as output_file:\n",
    "        cPickle.dump(X, output_file)\n",
    "        \n",
    "with open(f\"../embeddings/transformer/y.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(y, output_file)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:46:47.240525Z",
     "start_time": "2024-04-16T14:46:41.969263Z"
    }
   },
   "id": "671878413bfd7780",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(48890, 384)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(rf\"embeddings/transformer/transformer_{\"essay1\"}.pickle\", \"rb\") as input_file:\n",
    "     e1 = cPickle.load(input_file)\n",
    "e1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T15:25:15.167620Z",
     "start_time": "2024-04-16T15:25:15.128965Z"
    }
   },
   "id": "93a793dd5a609730",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    with open(rf\"../embeddings/transformer/transformer_essay{i}.pickle\", \"rb\") as input_file:\n",
    "        e = cPickle.load(input_file)\n",
    "    e.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58d805c4423bb01e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
